#+TITLE: Alert Implementation Scratchpad
#+DATE: 2025-07-21
#+STARTUP: overview

* Implementation Log

** 2025-07-21 Starting Implementation
- Plan created in docs/alert-implementation-plan.org
- Current state: Prometheus with 3 backup alerts, no AlertManager
- Goal: Full alerting with Slack notifications
- Services to monitor: Twenty CRM, Ghost CMS, Outline Wiki, n8n
- Hosts: shannon (monitoring), einstein, turing, newton (services)

** Next: Create Slack webhook secret and AlertManager config

** 2025-07-21 Need Slack Webhook URL
- User has existing Slack app configured
- Need to get webhook URL from Slack app settings
- Will add as alertmanager-slack-webhook.age secret for shannon host
- User will configure webhook later, proceeding with AlertManager setup

** 2025-07-21 Created AlertManager Configuration
- Created modules/system/linux/alertmanager.nix
- Configured Slack notifications to #alerts channel
- Added secret reference for webhook URL
- Set up alert routing: critical/warning → Slack, others → default
- Groups alerts by cluster/service/severity to reduce noise
- Next: Add AlertManager to monitoring.nix and create alert rules

** 2025-07-21 Connected AlertManager to Prometheus
- Added alertmanager.nix import to monitoring.nix
- Configured Prometheus to send alerts to localhost:9093
- Ready to test deploy before adding more alert rules

** 2025-07-21 Deploy Failed - Missing File
- Error: path alertmanager.nix does not exist
- Issue: File was created but not committed to git
- Deploy tool uses git tree, needs files to be tracked
- Need to commit changes before deploy

** 2025-07-21 Deploy Blocked - Missing Secret File
- Error: alertmanager-slack-webhook.age does not exist
- Cannot create agenix secrets without access to turing (key signing machine)
- Moving on to create alert rules while waiting for secret setup
- AlertManager config committed and ready, just needs webhook URL

** 2025-07-21 Created Comprehensive Alert Rules
- Created alert-rules/ directory with organized rule files
- service-alerts.yml: ServiceDown, ServiceSlowResponse for web endpoints
- infrastructure-alerts.yml: HostDown, HighCPU/Memory/Disk alerts
- container-alerts.yml: Container monitoring and resource alerts
- Added rule files to monitoring.nix ruleFiles configuration
- Ready to commit and test (pending webhook setup)

** 2025-07-21 Alert Testing Methods
Several ways to test alerts:

1. **Natural triggers** (wait for real issues):
   - Stop a service: `sudo systemctl stop ghost-cms`
   - Fill disk space: `dd if=/dev/zero of=/tmp/bigfile bs=1M count=1000`
   - CPU stress: `stress --cpu 8 --timeout 600s`

2. **Prometheus query testing**:
   - Visit http://shannon:9090/alerts to see current alert states
   - Test expressions in Prometheus query interface
   - Check if metrics are being collected properly

3. **AlertManager testing**:
   - Send test alert via amtool: `amtool alert add alertname=TestAlert`
   - Check AlertManager UI at http://shannon:9093
   - Verify routing rules and silencing work

4. **Slack delivery testing**:
   - Once webhook configured, test with simple alert
   - Verify message formatting and channel delivery
   - Test alert resolution notifications

Best approach: Start with Prometheus query testing, then trigger simple service down alert

** 2025-07-21 Secret Definition Already Exists
- The "alertmanager-slack-webhook.age" secret definition is already in secrets.nix
- Issue was deployment trying to reference non-existent .age file
- Need to create actual secret file with agenix from turing machine
- Secret is configured for shannon host access with user + shannon keys

** 2025-07-21 Deployment Successful - Starting Tests
- Fixed relative path from ../../ to ../../../ in alertmanager.nix
- Shannon deployed with AlertManager
- Beginning alert testing sequence

** 2025-07-21 Alert Testing Results
- AlertManager service running as "alertmanager.service"
- Found 9 active alerts in Prometheus
- Current firing alerts:
  - HostDown (critical): 10.0.0.3:9100 (turing) unreachable
  - DiskSpaceWarning: einstein /mnt/media at 89.9% usage
  - ContainerHighMemory: Multiple containers with high memory
- Sent test alert via AlertManager v2 API
- Check Slack #alerts channel for notifications

** 2025-07-21 Permission Issue Found
- Error: "permission denied" accessing /run/agenix/alertmanager-slack-webhook
- AlertManager runs as alertmanager user, but secret owned by root
- Fixed by setting owner/group to alertmanager in agenix config
- Need to redeploy for permission fix

** 2025-07-21 Permission Fix Deployed
- Fixed agenix permissions: owner/group set to alertmanager
- Restarted AlertManager service successfully
- No more permission errors in logs after restart
- Alerts are active in AlertManager (HostDown, etc.)
- Check Slack #alerts channel - notifications should be flowing now

** 2025-07-21 Alert Testing Complete
- Stopped Ghost CMS on newton - ServiceDown alert fired successfully
- Started Ghost CMS - alert cleared from Prometheus/AlertManager
- Issue: No resolved notification sent to Slack
- Fixed by adding send_resolved = true to Slack config
- Also removed turing from monitoring targets (only monitoring shannon, einstein, newton now)